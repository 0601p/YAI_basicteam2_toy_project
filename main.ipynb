{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/misrakahmed/vegetable-image-dataset\n",
    "\n",
    "데이터를 분류하는 데에 여러 모델들을 사용해 보고 성능, 학습 시간 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "# 필수 코드\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import visdom\n",
    "\n",
    "vis = visdom.Visdom()\n",
    "vis.close(env='main')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 256\n",
    "learning_rate = 1e-4\n",
    "epoch = 15\n",
    "\n",
    "image_size = 56\n",
    "class_num = 15\n",
    "class_name = ['Bean', 'Bitter_Gourd', 'Bottle_Gourd', 'Brinjal', 'Broccoli', 'Cabbage', 'Capsicum', 'Carrot', 'Cauliflower', 'Cucumber', 'Papaya', 'Potato', 'Pumpkin', 'Radish', 'Tomato']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data loader를 반환함\n",
    "def get_train_data_loaders(resize = False, rotate = False):\n",
    "    transforms = []\n",
    "\n",
    "    if rotate:\n",
    "        transforms.append(torchvision.transforms.transforms.RandomRotation(360))\n",
    "\n",
    "    if resize:\n",
    "        transforms.append(torchvision.transforms.RandomResizedCrop((image_size, image_size)))\n",
    "        \n",
    "    transforms.append(torchvision.transforms.Resize((image_size, image_size)))\n",
    "    transforms.append(torchvision.transforms.ToTensor())\n",
    "    transform = torchvision.transforms.Compose(transforms)\n",
    "\n",
    "    train_data = torchvision.datasets.ImageFolder(root='train', transform=transform)\n",
    "    train_data_loader =torch.utils.data.DataLoader(dataset = train_data, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=4)\n",
    "\n",
    "    return train_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data loader와 validation data loader를 반환함\n",
    "def get_test_validation_data_loaders():\n",
    "    transform = torchvision.transforms.Compose([torchvision.transforms.Resize((image_size, image_size)), torchvision.transforms.ToTensor()])\n",
    "    test_data = torchvision.datasets.ImageFolder(root='test', transform=transform)\n",
    "    validation_data = torchvision.datasets.ImageFolder(root='validation', transform=transform)\n",
    "\n",
    "    test_data_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size=batch_size, shuffle=False, drop_last=True, num_workers=4)\n",
    "    validation_data_loader =torch.utils.data.DataLoader(dataset = validation_data, batch_size=batch_size, shuffle=False, drop_last=True, num_workers=4)\n",
    "\n",
    "    return test_data_loader, validation_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, data_loader):\n",
    "    with torch.no_grad():\n",
    "        accuracy = 0\n",
    "        for X, Y in data_loader:\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            prediction = model(X)\n",
    "            correct_prediction = torch.argmax(prediction, dim=1) == Y\n",
    "            accuracy += correct_prediction.float().mean()\n",
    "        accuracy /= len(data_loader)\n",
    "        print(\"accuracy : {:.4f}%\".format(accuracy.item() * 100))\n",
    "    return accuracy.item() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model을 data_loader로 epoch만큼 학습함, print_loss가 True이면 trainloss를 출력함\n",
    "def train_model(model, data_loader, test_loader, epochs, print_loss=False):\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    total_batch = len(data_loader)\n",
    "\n",
    "    if print_loss:\n",
    "        loss_plot = vis.line(Y=torch.Tensor(1).zero_(),opts=dict(title='loss_tracker', legend=['loss'], showlegend=True), env='main')\n",
    "        acc_plot = vis.line(Y=torch.Tensor(1).zero_(),opts=dict(title='accuracy_tracker', legend=['accuracy'], showlegend=True), env='main')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        avg_cost = 0.0\n",
    "        for X, Y in data_loader:\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            output = model(X)\n",
    "            loss = criterion(output, Y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_cost += loss/total_batch\n",
    "        \n",
    "        if print_loss:\n",
    "            print('[EPOCH:{:3d}] cost:{:.5f}'.format(epoch + 1, avg_cost))\n",
    "            vis.line(X=torch.Tensor([epoch]), Y=torch.Tensor([avg_cost]), win=loss_plot, update=\"append\")\n",
    "            acc = test_model(model, test_loader)\n",
    "            vis.line(X=torch.Tensor([epoch]), Y=torch.Tensor([acc]), win=loss_plot, update=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected model\n",
    "class FCmodel(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        layer_list = []\n",
    "        in_size = config[0]\n",
    "        for i in range(1, len(config) - 1):\n",
    "            out_size = config[i]\n",
    "            layer_list.append(torch.nn.Linear(in_size, out_size, bias=True))\n",
    "            layer_list.append(torch.nn.ReLU())\n",
    "            in_size = out_size\n",
    "        \n",
    "        out_size = config[-1]\n",
    "        layer_list.append(torch.nn.Linear(in_size, out_size, bias=True))\n",
    "\n",
    "        self.layers = torch.nn.Sequential(*layer_list)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self, config, config_fc = None):\n",
    "        super().__init__()\n",
    "        layer_list = []\n",
    "        channel_in_size = 3\n",
    "        in_size = image_size\n",
    "        for cont in config:\n",
    "            if cont == 'M':\n",
    "                layer_list.append(torch.nn.MaxPool2d(2))\n",
    "                in_size = in_size // 2\n",
    "            else:\n",
    "                channel, kernel_size, padding = cont\n",
    "                layer_list.append(torch.nn.Conv2d(channel_in_size, channel, kernel_size, padding=padding))\n",
    "                layer_list.append(torch.nn.ReLU())\n",
    "                channel_in_size = channel\n",
    "                in_size = in_size - kernel_size + 2 * padding + 1\n",
    "        \n",
    "        self.layers = torch.nn.Sequential(*layer_list)\n",
    "\n",
    "        if config_fc == None:\n",
    "            self.fc = FCmodel([in_size * in_size * channel_in_size, 128, 32, class_num])\n",
    "        else:\n",
    "            self.fc = FCmodel(config_fc)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG model\n",
    "class VGG(torch.nn.Module):\n",
    "    def __init__(self, config, init_weights=True):\n",
    "        super(VGG, self).__init__()\n",
    "        \n",
    "        channel_in_size = 3\n",
    "        layer_list = []\n",
    "        for cont in config:\n",
    "            if cont == 'M':\n",
    "                layer_list.append(torch.nn.MaxPool2d(2))\n",
    "            else:\n",
    "                layer_list.append(torch.nn.Conv2d(channel_in_size, cont, 3, padding=1))\n",
    "                layer_list.append(torch.nn.ReLU())\n",
    "                channel_in_size = cont\n",
    "        \n",
    "        self.features = torch.nn.Sequential(*layer_list)\n",
    "\n",
    "        \n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((7, 7))\n",
    "        \n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(channel_in_size * 7 * 7, 512),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(512, 128),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(128, class_num),\n",
    "        )#FC layer\n",
    "        \n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x) #Convolution \n",
    "        x = self.avgpool(x) # avgpool\n",
    "        x = x.view(x.size(0), -1) #\n",
    "        x = self.classifier(x) #FC layer\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    torch.nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, torch.nn.BatchNorm2d):\n",
    "                torch.nn.init.constant_(m.weight, 1)\n",
    "                torch.nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.normal_(m.weight, 0, 0.01)\n",
    "                torch.nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (13): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (14): ReLU()\n",
      "    (15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): ReLU()\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=512, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=15, bias=True)\n",
      "  )\n",
      ")\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (13): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (14): ReLU()\n",
      "    (15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): ReLU()\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=512, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=15, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#model1 = FCmodel([image_size*image_size*3, 2048, 512, 128, class_num]).to(device)\n",
    "#model2 = CNN([(32, 3, 0), 'M', (64, 3, 0), 'M', (128, 3, 0), 'M']).to(device)\n",
    "model3 = VGG([64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512]).to(device)\n",
    "print(model3)\n",
    "print(model3)\n",
    "train_loader = get_train_data_loaders()\n",
    "test_loader, valid_loader = get_test_validation_data_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9732\\2929462498.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9732\\3989440114.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, data_loader, test_loader, epochs, print_loss)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mavg_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model3, train_loader, test_loader, epoch, print_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16732\\1757765691.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_test_validation_data_loaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "test_model(model2, train_loader)\n",
    "\n",
    "test_model(model2, test_loader)\n",
    "test_model(model2, valid_loader)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9fbae1f717372853f059f30b1665e3de40574a1ddd27eaeebd4164e889f9321"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
