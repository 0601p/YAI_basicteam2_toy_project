{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/misrakahmed/vegetable-image-dataset\n",
    "\n",
    "데이터를 분류하는 데에 여러 모델들을 사용해 보고 성능, 학습 시간 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "# 필수 코드\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import visdom\n",
    "\n",
    "vis = visdom.Visdom()\n",
    "vis.close(env='main')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 1800\n",
    "learning_rate = 1e-3\n",
    "epoch = 50\n",
    "\n",
    "image_size = 56\n",
    "class_num = 15\n",
    "class_name = ['Bean', 'Bitter_Gourd', 'Bottle_Gourd', 'Brinjal', 'Broccoli', 'Cabbage', 'Capsicum', 'Carrot', 'Cauliflower', 'Cucumber', 'Papaya', 'Potato', 'Pumpkin', 'Radish', 'Tomato']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data loader를 반환함\n",
    "def get_train_data_loaders(resize = False, rotate = False):\n",
    "    transforms = []\n",
    "\n",
    "    if rotate:\n",
    "        transforms.append(torchvision.transforms.transforms.RandomRotation(360))\n",
    "\n",
    "    if resize:\n",
    "        transforms.append(torchvision.transforms.RandomResizedCrop((image_size, image_size)))\n",
    "        \n",
    "    transforms.append(torchvision.transforms.Resize((image_size, image_size)))\n",
    "    transforms.append(torchvision.transforms.ToTensor())\n",
    "    transform = torchvision.transforms.Compose(transforms)\n",
    "\n",
    "    train_data = torchvision.datasets.ImageFolder(root='train', transform=transform)\n",
    "    train_data_loader =torch.utils.data.DataLoader(dataset = train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    return train_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data loader와 validation data loader를 반환함\n",
    "def get_test_validation_data_loaders():\n",
    "    transform = torchvision.transforms.Compose([torchvision.transforms.Resize((image_size, image_size)), torchvision.transforms.ToTensor()])\n",
    "    test_data = torchvision.datasets.ImageFolder(root='test', transform=transform)\n",
    "    validation_data = torchvision.datasets.ImageFolder(root='validation', transform=transform)\n",
    "\n",
    "    test_data_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    validation_data_loader =torch.utils.data.DataLoader(dataset = validation_data, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "    return test_data_loader, validation_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, data_loader):\n",
    "    with torch.no_grad():\n",
    "        accuracy = 0\n",
    "        for X, Y in data_loader:\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            prediction = model(X)\n",
    "            correct_prediction = torch.argmax(prediction, dim=1) == Y\n",
    "            accuracy += correct_prediction.float().mean()\n",
    "        accuracy /= len(data_loader)\n",
    "        print(\"accuracy : {:.4f}%\".format(accuracy.item() * 100))\n",
    "        del X\n",
    "        del Y\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return accuracy.item() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model을 data_loader로 epoch만큼 학습함, print_loss가 True이면 trainloss를 출력함\n",
    "def train_model(model, data_loader, test_loader, opt, epochs, print_loss=False):\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = opt(model.parameters(), lr=learning_rate)\n",
    "    total_batch = len(data_loader)\n",
    "\n",
    "    if print_loss:\n",
    "        loss_plot = vis.line(Y=torch.Tensor(1).zero_(),opts=dict(title='loss_tracker', legend=['loss'], showlegend=True), env='main')\n",
    "        acc_plot = vis.line(Y=torch.Tensor(1).zero_(),opts=dict(title='accuracy_tracker', legend=['accuracy'], showlegend=True), env='main')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        avg_cost = 0.0\n",
    "        for X, Y in data_loader:\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            output = model(X)\n",
    "            loss = criterion(output, Y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_cost += loss/total_batch\n",
    "        \n",
    "        del X\n",
    "        del Y\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        if print_loss:\n",
    "            print('[EPOCH:{:3d}] cost:{:.5f}'.format(epoch + 1, avg_cost))\n",
    "            vis.line(X=torch.Tensor([epoch]), Y=torch.Tensor([avg_cost]), win=loss_plot, update=\"append\")\n",
    "            acc = test_model(model, test_loader)\n",
    "            vis.line(X=torch.Tensor([epoch]), Y=torch.Tensor([acc]), win=acc_plot, update=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected model\n",
    "class FCmodel(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        layer_list = []\n",
    "        in_size = config[0]\n",
    "        for i in range(1, len(config) - 1):\n",
    "            out_size = config[i]\n",
    "            layer_list.append(torch.nn.Linear(in_size, out_size, bias=True))\n",
    "            layer_list.append(torch.nn.ReLU())\n",
    "            in_size = out_size\n",
    "        \n",
    "        out_size = config[-1]\n",
    "        layer_list.append(torch.nn.Linear(in_size, out_size, bias=True))\n",
    "\n",
    "        self.layers = torch.nn.Sequential(*layer_list)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self, config, config_fc = None):\n",
    "        super().__init__()\n",
    "        layer_list = []\n",
    "        channel_in_size = 3\n",
    "        in_size = image_size\n",
    "        for cont in config:\n",
    "            if cont == 'M':\n",
    "                layer_list.append(torch.nn.MaxPool2d(2))\n",
    "                in_size = in_size // 2\n",
    "            else:\n",
    "                channel, kernel_size, padding = cont\n",
    "                layer_list.append(torch.nn.Conv2d(channel_in_size, channel, kernel_size, padding=padding))\n",
    "                layer_list.append(torch.nn.ReLU())\n",
    "                channel_in_size = channel\n",
    "                in_size = in_size - kernel_size + 2 * padding + 1\n",
    "        \n",
    "        self.layers = torch.nn.Sequential(*layer_list)\n",
    "\n",
    "        if config_fc == None:\n",
    "            self.fc = FCmodel([in_size * in_size * channel_in_size, 128, 32, class_num])\n",
    "        else:\n",
    "            self.fc = FCmodel(config_fc)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG model\n",
    "class VGG(torch.nn.Module):\n",
    "    def __init__(self, config, init_weights=True):\n",
    "        super(VGG, self).__init__()\n",
    "        \n",
    "        channel_in_size = 3\n",
    "        layer_list = []\n",
    "        for cont in config:\n",
    "            if cont == 'M':\n",
    "                layer_list.append(torch.nn.MaxPool2d(2))\n",
    "            else:\n",
    "                layer_list.append(torch.nn.Conv2d(channel_in_size, cont, 3, padding=1))\n",
    "                layer_list.append(torch.nn.ReLU())\n",
    "                channel_in_size = cont\n",
    "        \n",
    "        self.features = torch.nn.Sequential(*layer_list)\n",
    "\n",
    "        \n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((7, 7))\n",
    "        \n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(channel_in_size * 7 * 7, 512),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(512, 128),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(128, class_num),\n",
    "        )#FC layer\n",
    "        \n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x) #Convolution \n",
    "        x = self.avgpool(x) # avgpool\n",
    "        x = x.view(x.size(0), -1) #\n",
    "        x = self.classifier(x) #FC layer\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    torch.nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, torch.nn.BatchNorm2d):\n",
    "                torch.nn.init.constant_(m.weight, 1)\n",
    "                torch.nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.normal_(m.weight, 0, 0.01)\n",
    "                torch.nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionA(torch.nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(InceptionA, self).__init__()\n",
    "        \n",
    "        self.branch_pool = torch.nn.Conv2d(in_channels, 24, kernel_size=1)\n",
    "        \n",
    "        self.branch1x1 = torch.nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        \n",
    "        self.branch5x5_1 = torch.nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        self.branch5x5_2 = torch.nn.Conv2d(16,24,kernel_size=5, padding=2)\n",
    "        \n",
    "        self.branch3x3dbl_1 = torch.nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = torch.nn.Conv2d(16, 24, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3 = torch.nn.Conv2d(24, 24, kernel_size=3, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "        \n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "        \n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "        \n",
    "        branch_pool = torch.nn.functional.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "        \n",
    "        outputs = [branch1x1,  branch5x5, branch3x3dbl, branch_pool]\n",
    "        \n",
    "        return torch.cat(outputs, 1)\n",
    "    \n",
    "class InceptionNet(torch.nn.Module):\n",
    "    def __init__(self, activation = 'ReLU'):\n",
    "        super(InceptionNet, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3,10,kernel_size=5)\n",
    "        self.conv2 = torch.nn.Conv2d(88,20,kernel_size=5)\n",
    "        self.conv3 = torch.nn.Conv2d(88,30,kernel_size=5)\n",
    "        \n",
    "        self.incept1 = InceptionA(in_channels=10)\n",
    "        self.incept2 = InceptionA(in_channels=20)\n",
    "        self.incept3 = InceptionA(in_channels=30)\n",
    "        af = {'ReLU' : torch.nn.ReLU(), 'Sigmoid' : torch.nn.Sigmoid(), 'LeakyReLU' : torch.nn.LeakyReLU(), 'tanh' : torch.nn.Tanh()}\n",
    "        self.activation = af[activation]\n",
    "\n",
    "        self.mp = torch.nn.MaxPool2d(2)\n",
    "        self.fc = torch.nn.Linear(792,15)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = self.activation(self.mp(self.conv1(x)))\n",
    "        x = self.incept1(x)\n",
    "        x = self.activation(self.mp(self.conv2(x)))\n",
    "        x = self.incept2(x)\n",
    "        x = self.activation(self.mp(self.conv3(x)))\n",
    "        x = self.incept3(x)\n",
    "        x = x.view(in_size, -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1 = FCmodel([image_size*image_size*3, 2048, 512, 128, class_num]).to(device)\n",
    "#model2 = CNN([(32, 3, 0), 'M', (64, 3, 0), 'M', (128, 3, 0), 'M']).to(device)\n",
    "#model3 = VGG([64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512]).to(device)\n",
    "# model4 = InceptionNet('ReLU').to(device)\n",
    "# print(model4)\n",
    "train_loader = get_train_data_loaders()\n",
    "test_loader, valid_loader = get_test_validation_data_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(model4, train_loader, test_loader, torch.optim.Adam, epoch, print_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model4.state_dict(), './model/inception_relu_50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model4\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# model4 = InceptionNet('Sigmoid').to(device)\n",
    "# train_model(model4, train_loader, test_loader, torch.optim.Adam, epoch, print_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model4.state_dict(), './model/inception_Sigmoid_50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model4\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# model4 = InceptionNet('LeakyReLU').to(device)\n",
    "# train_model(model4, train_loader, test_loader, torch.optim.Adam, epoch, print_loss=True)\n",
    "# torch.save(model4.state_dict(), './model/inception_LeakyReLU_50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model4\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# model4 = InceptionNet('tanh').to(device)\n",
    "# train_model(model4, train_loader, test_loader, torch.optim.Adam, epoch, print_loss=True)\n",
    "# torch.save(model4.state_dict(), './model/inception_tanh_50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH:  1] cost:2.70881\n",
      "accuracy : 11.1111%\n",
      "[EPOCH:  2] cost:2.70877\n",
      "accuracy : 11.1111%\n",
      "[EPOCH:  3] cost:2.70873\n",
      "accuracy : 11.1111%\n",
      "[EPOCH:  4] cost:2.70886\n",
      "accuracy : 11.1111%\n",
      "[EPOCH:  5] cost:2.70880\n",
      "accuracy : 11.1111%\n",
      "[EPOCH:  6] cost:2.70869\n",
      "accuracy : 11.1111%\n",
      "[EPOCH:  7] cost:2.70879\n",
      "accuracy : 11.1111%\n",
      "[EPOCH:  8] cost:2.70890\n",
      "accuracy : 11.1111%\n",
      "[EPOCH:  9] cost:2.70871\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 10] cost:2.70872\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 11] cost:2.70884\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 12] cost:2.70879\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 13] cost:2.70870\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 14] cost:2.70877\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 15] cost:2.70871\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 16] cost:2.70874\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 17] cost:2.70869\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 18] cost:2.70873\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 19] cost:2.70867\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 20] cost:2.70867\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 21] cost:2.70873\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 22] cost:2.70871\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 23] cost:2.70868\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 24] cost:2.70865\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 25] cost:2.70865\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 26] cost:2.70868\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 27] cost:2.70873\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 28] cost:2.70856\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 29] cost:2.70865\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 30] cost:2.70865\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 31] cost:2.70862\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 32] cost:2.70861\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 33] cost:2.70864\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 34] cost:2.70862\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 35] cost:2.70868\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 36] cost:2.70867\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 37] cost:2.70853\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 38] cost:2.70866\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 39] cost:2.70859\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 40] cost:2.70861\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 41] cost:2.70862\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 42] cost:2.70856\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 43] cost:2.70850\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 44] cost:2.70858\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 45] cost:2.70862\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 46] cost:2.70861\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 47] cost:2.70864\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 48] cost:2.70855\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 49] cost:2.70852\n",
      "accuracy : 11.1111%\n",
      "[EPOCH: 50] cost:2.70860\n",
      "accuracy : 11.1111%\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model4 = InceptionNet('ReLU').to(device)\n",
    "train_model(model4, train_loader, test_loader, torch.optim.SGD, epoch, print_loss=True)\n",
    "torch.save(model4.state_dict(), './model/inception_SGD_50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH:  1] cost:2.69407\n",
      "accuracy : 17.2778%\n",
      "[EPOCH:  2] cost:2.55275\n",
      "accuracy : 3.1667%\n",
      "[EPOCH:  3] cost:2.53134\n",
      "accuracy : 9.8889%\n",
      "[EPOCH:  4] cost:2.35331\n",
      "accuracy : 7.3889%\n",
      "[EPOCH:  5] cost:2.35185\n",
      "accuracy : 11.8333%\n",
      "[EPOCH:  6] cost:2.28350\n",
      "accuracy : 11.2222%\n",
      "[EPOCH:  7] cost:2.28197\n",
      "accuracy : 13.6111%\n",
      "[EPOCH:  8] cost:2.21946\n",
      "accuracy : 16.7222%\n",
      "[EPOCH:  9] cost:2.21716\n",
      "accuracy : 23.7778%\n",
      "[EPOCH: 10] cost:2.17881\n",
      "accuracy : 17.2222%\n",
      "[EPOCH: 11] cost:2.14687\n",
      "accuracy : 19.6667%\n",
      "[EPOCH: 12] cost:2.10660\n",
      "accuracy : 20.3889%\n",
      "[EPOCH: 13] cost:2.08002\n",
      "accuracy : 19.5556%\n",
      "[EPOCH: 14] cost:2.02597\n",
      "accuracy : 26.7778%\n",
      "[EPOCH: 15] cost:1.96330\n",
      "accuracy : 30.3333%\n",
      "[EPOCH: 16] cost:1.90296\n",
      "accuracy : 31.7222%\n",
      "[EPOCH: 17] cost:1.87523\n",
      "accuracy : 33.0000%\n",
      "[EPOCH: 18] cost:1.88884\n",
      "accuracy : 33.5000%\n",
      "[EPOCH: 19] cost:1.79524\n",
      "accuracy : 35.5556%\n",
      "[EPOCH: 20] cost:1.76236\n",
      "accuracy : 36.0556%\n",
      "[EPOCH: 21] cost:1.76050\n",
      "accuracy : 31.3333%\n",
      "[EPOCH: 22] cost:1.81905\n",
      "accuracy : 36.3889%\n",
      "[EPOCH: 23] cost:1.72316\n",
      "accuracy : 37.8889%\n",
      "[EPOCH: 24] cost:1.71036\n",
      "accuracy : 35.5556%\n",
      "[EPOCH: 25] cost:1.74364\n",
      "accuracy : 38.1111%\n",
      "[EPOCH: 26] cost:1.69203\n",
      "accuracy : 39.4444%\n",
      "[EPOCH: 27] cost:1.71659\n",
      "accuracy : 41.1111%\n",
      "[EPOCH: 28] cost:1.66414\n",
      "accuracy : 41.0000%\n",
      "[EPOCH: 29] cost:1.65136\n",
      "accuracy : 39.0000%\n",
      "[EPOCH: 30] cost:1.65639\n",
      "accuracy : 41.2222%\n",
      "[EPOCH: 31] cost:1.62256\n",
      "accuracy : 40.5000%\n",
      "[EPOCH: 32] cost:1.62354\n",
      "accuracy : 43.2778%\n",
      "[EPOCH: 33] cost:1.69512\n",
      "accuracy : 42.2222%\n",
      "[EPOCH: 34] cost:1.61953\n",
      "accuracy : 42.0556%\n",
      "[EPOCH: 35] cost:1.58974\n",
      "accuracy : 40.2222%\n",
      "[EPOCH: 36] cost:1.57776\n",
      "accuracy : 42.2222%\n",
      "[EPOCH: 37] cost:1.58275\n",
      "accuracy : 39.8333%\n",
      "[EPOCH: 38] cost:1.60079\n",
      "accuracy : 42.6111%\n",
      "[EPOCH: 39] cost:1.56242\n",
      "accuracy : 43.0556%\n",
      "[EPOCH: 40] cost:1.57424\n",
      "accuracy : 40.0556%\n",
      "[EPOCH: 41] cost:1.58252\n",
      "accuracy : 45.6111%\n",
      "[EPOCH: 42] cost:1.54507\n",
      "accuracy : 44.5556%\n",
      "[EPOCH: 43] cost:1.52969\n",
      "accuracy : 45.3333%\n",
      "[EPOCH: 44] cost:1.52896\n",
      "accuracy : 45.0000%\n",
      "[EPOCH: 45] cost:1.52843\n",
      "accuracy : 46.6667%\n",
      "[EPOCH: 46] cost:1.52970\n",
      "accuracy : 47.5000%\n",
      "[EPOCH: 47] cost:1.53875\n",
      "accuracy : 46.5000%\n",
      "[EPOCH: 48] cost:1.53197\n",
      "accuracy : 44.7778%\n",
      "[EPOCH: 49] cost:1.50390\n",
      "accuracy : 43.5556%\n",
      "[EPOCH: 50] cost:1.49135\n",
      "accuracy : 47.1667%\n"
     ]
    }
   ],
   "source": [
    "del model4\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model4 = InceptionNet('ReLU').to(device)\n",
    "train_model(model4, train_loader, test_loader, torch.optim.Adagrad, epoch, print_loss=True)\n",
    "torch.save(model4.state_dict(), './model/inception_Adagrad_50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH:  1] cost:33.22563\n",
      "accuracy : 1.5000%\n",
      "[EPOCH:  2] cost:2.86175\n",
      "accuracy : 13.1111%\n",
      "[EPOCH:  3] cost:2.64636\n",
      "accuracy : 13.3889%\n",
      "[EPOCH:  4] cost:2.56144\n",
      "accuracy : 9.7778%\n",
      "[EPOCH:  5] cost:2.49616\n",
      "accuracy : 8.2222%\n",
      "[EPOCH:  6] cost:2.50911\n",
      "accuracy : 8.5000%\n",
      "[EPOCH:  7] cost:2.47144\n",
      "accuracy : 9.2222%\n",
      "[EPOCH:  8] cost:2.44909\n",
      "accuracy : 8.8333%\n",
      "[EPOCH:  9] cost:2.44832\n",
      "accuracy : 12.6667%\n",
      "[EPOCH: 10] cost:2.41934\n",
      "accuracy : 15.5556%\n",
      "[EPOCH: 11] cost:2.40281\n",
      "accuracy : 16.8333%\n",
      "[EPOCH: 12] cost:2.40012\n",
      "accuracy : 12.6667%\n",
      "[EPOCH: 13] cost:2.37652\n",
      "accuracy : 20.2222%\n",
      "[EPOCH: 14] cost:2.35835\n",
      "accuracy : 21.3333%\n",
      "[EPOCH: 15] cost:2.33851\n",
      "accuracy : 17.7778%\n",
      "[EPOCH: 16] cost:2.35462\n",
      "accuracy : 19.8333%\n",
      "[EPOCH: 17] cost:2.32705\n",
      "accuracy : 22.2778%\n",
      "[EPOCH: 18] cost:2.37992\n",
      "accuracy : 26.0556%\n",
      "[EPOCH: 19] cost:2.27824\n",
      "accuracy : 18.9444%\n",
      "[EPOCH: 20] cost:2.32409\n",
      "accuracy : 28.0000%\n",
      "[EPOCH: 21] cost:2.24536\n",
      "accuracy : 24.7222%\n",
      "[EPOCH: 22] cost:2.23793\n",
      "accuracy : 16.2778%\n",
      "[EPOCH: 23] cost:2.22431\n",
      "accuracy : 17.7222%\n",
      "[EPOCH: 24] cost:2.22952\n",
      "accuracy : 31.0000%\n",
      "[EPOCH: 25] cost:2.44820\n",
      "accuracy : 23.4444%\n",
      "[EPOCH: 26] cost:2.19327\n",
      "accuracy : 23.5000%\n",
      "[EPOCH: 27] cost:2.13724\n",
      "accuracy : 23.6111%\n",
      "[EPOCH: 28] cost:2.21203\n",
      "accuracy : 32.7222%\n",
      "[EPOCH: 29] cost:2.13937\n",
      "accuracy : 21.6111%\n",
      "[EPOCH: 30] cost:2.13358\n",
      "accuracy : 29.7222%\n",
      "[EPOCH: 31] cost:2.06199\n",
      "accuracy : 31.7778%\n",
      "[EPOCH: 32] cost:2.15027\n",
      "accuracy : 26.0000%\n",
      "[EPOCH: 33] cost:2.14025\n",
      "accuracy : 26.3333%\n",
      "[EPOCH: 34] cost:2.04613\n",
      "accuracy : 29.8889%\n",
      "[EPOCH: 35] cost:2.03278\n",
      "accuracy : 32.7778%\n",
      "[EPOCH: 36] cost:2.11770\n",
      "accuracy : 21.7778%\n",
      "[EPOCH: 37] cost:1.98779\n",
      "accuracy : 33.9444%\n",
      "[EPOCH: 38] cost:2.08496\n",
      "accuracy : 27.2778%\n",
      "[EPOCH: 39] cost:1.93267\n",
      "accuracy : 32.5556%\n",
      "[EPOCH: 40] cost:2.05138\n",
      "accuracy : 34.1111%\n",
      "[EPOCH: 41] cost:1.95838\n",
      "accuracy : 36.6667%\n",
      "[EPOCH: 42] cost:1.79999\n",
      "accuracy : 34.7222%\n",
      "[EPOCH: 43] cost:2.11156\n",
      "accuracy : 34.5556%\n",
      "[EPOCH: 44] cost:1.77554\n",
      "accuracy : 32.0556%\n",
      "[EPOCH: 45] cost:1.75646\n",
      "accuracy : 36.1111%\n",
      "[EPOCH: 46] cost:2.01238\n",
      "accuracy : 29.3889%\n",
      "[EPOCH: 47] cost:1.75839\n",
      "accuracy : 30.8889%\n",
      "[EPOCH: 48] cost:2.17472\n",
      "accuracy : 23.3333%\n",
      "[EPOCH: 49] cost:1.95875\n",
      "accuracy : 36.2778%\n",
      "[EPOCH: 50] cost:1.65879\n",
      "accuracy : 38.0000%\n"
     ]
    }
   ],
   "source": [
    "del model4\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model4 = InceptionNet('ReLU').to(device)\n",
    "train_model(model4, train_loader, test_loader, torch.optim.RMSprop, epoch, print_loss=True)\n",
    "torch.save(model4.state_dict(), './model/inception_RMSprop_50')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9fbae1f717372853f059f30b1665e3de40574a1ddd27eaeebd4164e889f9321"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
